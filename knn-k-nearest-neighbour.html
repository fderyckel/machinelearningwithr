<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Machine Learning with R</title>
  <meta name="description" content="This book is about using R for machine learning purposes.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Machine Learning with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book is about using R for machine learning purposes." />
  <meta name="github-repo" content="fderyckel/machinelearningwithr" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Machine Learning with R" />
  
  <meta name="twitter:description" content="This book is about using R for machine learning purposes." />
  

<meta name="author" content="François de Ryckel">


<meta name="date" content="2017-09-30">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="logistic-regression.html">
<link rel="next" href="trees-and-classification.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Machine Learning with R</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Tests and inferences</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#t-tests"><i class="fa fa-check"></i><b>2.1</b> T-tests</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mlr.html"><a href="mlr.html"><i class="fa fa-check"></i><b>3</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="mlr.html"><a href="mlr.html#single-variable-regression"><i class="fa fa-check"></i><b>3.1</b> Single variable regression</a><ul>
<li class="chapter" data-level="3.1.1" data-path="mlr.html"><a href="mlr.html#first-example.-predicting-wine-price"><i class="fa fa-check"></i><b>3.1.1</b> First example. Predicting wine price</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="mlr.html"><a href="mlr.html#multi-variables-regression"><i class="fa fa-check"></i><b>3.2</b> Multi-variables regression</a><ul>
<li class="chapter" data-level="3.2.1" data-path="mlr.html"><a href="mlr.html#first-example.-predicting-wine-price-1"><i class="fa fa-check"></i><b>3.2.1</b> First example. Predicting wine price</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>4</b> Logistic Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#the-logistic-equation."><i class="fa fa-check"></i><b>4.2</b> The logistic equation.</a></li>
<li class="chapter" data-level="4.3" data-path="logistic-regression.html"><a href="logistic-regression.html#performance-of-logistic-regression-model"><i class="fa fa-check"></i><b>4.3</b> Performance of Logistic Regression Model</a></li>
<li class="chapter" data-level="4.4" data-path="logistic-regression.html"><a href="logistic-regression.html#setting-up"><i class="fa fa-check"></i><b>4.4</b> Setting up</a></li>
<li class="chapter" data-level="4.5" data-path="logistic-regression.html"><a href="logistic-regression.html#example-1---graduate-admission"><i class="fa fa-check"></i><b>4.5</b> Example 1 - Graduate Admission</a></li>
<li class="chapter" data-level="4.6" data-path="logistic-regression.html"><a href="logistic-regression.html#example-2---diabetes"><i class="fa fa-check"></i><b>4.6</b> Example 2 - Diabetes</a><ul>
<li class="chapter" data-level="4.6.1" data-path="logistic-regression.html"><a href="logistic-regression.html#accounting-for-missing-values"><i class="fa fa-check"></i><b>4.6.1</b> Accounting for missing values</a></li>
<li class="chapter" data-level="4.6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#imputting-missing-values"><i class="fa fa-check"></i><b>4.6.2</b> Imputting Missing Values</a></li>
<li class="chapter" data-level="4.6.3" data-path="logistic-regression.html"><a href="logistic-regression.html#roc-and-auc"><i class="fa fa-check"></i><b>4.6.3</b> ROC and AUC</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="logistic-regression.html"><a href="logistic-regression.html#references"><i class="fa fa-check"></i><b>4.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="knn-k-nearest-neighbour.html"><a href="knn-k-nearest-neighbour.html"><i class="fa fa-check"></i><b>5</b> KNN - K Nearest Neighbour</a><ul>
<li class="chapter" data-level="5.1" data-path="knn-k-nearest-neighbour.html"><a href="knn-k-nearest-neighbour.html#example-1.-prostate-cancer-dataset"><i class="fa fa-check"></i><b>5.1</b> Example 1. Prostate Cancer dataset</a></li>
<li class="chapter" data-level="5.2" data-path="knn-k-nearest-neighbour.html"><a href="knn-k-nearest-neighbour.html#example-2.-wine-dataset"><i class="fa fa-check"></i><b>5.2</b> Example 2. Wine dataset</a><ul>
<li class="chapter" data-level="5.2.1" data-path="knn-k-nearest-neighbour.html"><a href="knn-k-nearest-neighbour.html#understand-the-data"><i class="fa fa-check"></i><b>5.2.1</b> Understand the data</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="knn-k-nearest-neighbour.html"><a href="knn-k-nearest-neighbour.html#references-1"><i class="fa fa-check"></i><b>5.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="trees-and-classification.html"><a href="trees-and-classification.html"><i class="fa fa-check"></i><b>6</b> Trees and Classification</a><ul>
<li class="chapter" data-level="6.1" data-path="trees-and-classification.html"><a href="trees-and-classification.html#introduction-1"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="trees-and-classification.html"><a href="trees-and-classification.html#first-example."><i class="fa fa-check"></i><b>6.2</b> First example.</a></li>
<li class="chapter" data-level="6.3" data-path="trees-and-classification.html"><a href="trees-and-classification.html#second-example."><i class="fa fa-check"></i><b>6.3</b> Second Example.</a></li>
<li class="chapter" data-level="6.4" data-path="trees-and-classification.html"><a href="trees-and-classification.html#how-does-a-tree-decide-where-to-split"><i class="fa fa-check"></i><b>6.4</b> How does a tree decide where to split?</a></li>
<li class="chapter" data-level="6.5" data-path="trees-and-classification.html"><a href="trees-and-classification.html#third-example."><i class="fa fa-check"></i><b>6.5</b> Third example.</a></li>
<li class="chapter" data-level="6.6" data-path="trees-and-classification.html"><a href="trees-and-classification.html#references-2"><i class="fa fa-check"></i><b>6.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>7</b> Principal Component Analysis</a><ul>
<li class="chapter" data-level="7.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#pca-on-an-easy-example."><i class="fa fa-check"></i><b>7.1</b> PCA on an easy example.</a></li>
<li class="chapter" data-level="7.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#attempt-of-pca-on-technical-indicators."><i class="fa fa-check"></i><b>7.2</b> Attempt of PCA on technical indicators.</a></li>
<li class="chapter" data-level="7.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#doing-pca-and-pcr-with-the-pls-package"><i class="fa fa-check"></i><b>7.3</b> Doing PCA and PCR with the PLS package</a></li>
<li class="chapter" data-level="7.4" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#references."><i class="fa fa-check"></i><b>7.4</b> References.</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="case-study-mushrooms-classification.html"><a href="case-study-mushrooms-classification.html"><i class="fa fa-check"></i><b>8</b> Case Study - Mushrooms Classification</a><ul>
<li class="chapter" data-level="8.1" data-path="case-study-mushrooms-classification.html"><a href="case-study-mushrooms-classification.html#import-the-data"><i class="fa fa-check"></i><b>8.1</b> Import the data</a></li>
<li class="chapter" data-level="8.2" data-path="case-study-mushrooms-classification.html"><a href="case-study-mushrooms-classification.html#tidy-the-data"><i class="fa fa-check"></i><b>8.2</b> Tidy the data</a></li>
<li class="chapter" data-level="8.3" data-path="case-study-mushrooms-classification.html"><a href="case-study-mushrooms-classification.html#understand-the-data-1"><i class="fa fa-check"></i><b>8.3</b> Understand the data</a><ul>
<li class="chapter" data-level="8.3.1" data-path="case-study-mushrooms-classification.html"><a href="case-study-mushrooms-classification.html#transform-the-data"><i class="fa fa-check"></i><b>8.3.1</b> Transform the data</a></li>
<li class="chapter" data-level="8.3.2" data-path="case-study-mushrooms-classification.html"><a href="case-study-mushrooms-classification.html#visualize-the-data"><i class="fa fa-check"></i><b>8.3.2</b> Visualize the data</a></li>
<li class="chapter" data-level="8.3.3" data-path="case-study-mushrooms-classification.html"><a href="case-study-mushrooms-classification.html#modeling"><i class="fa fa-check"></i><b>8.3.3</b> Modeling</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="case-study-mushrooms-classification.html"><a href="case-study-mushrooms-classification.html#communication"><i class="fa fa-check"></i><b>8.4</b> Communication</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html"><i class="fa fa-check"></i><b>9</b> Case Study - Predicting Survivalship on the Titanic</a><ul>
<li class="chapter" data-level="9.1" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html#import-the-data."><i class="fa fa-check"></i><b>9.1</b> Import the data.</a></li>
<li class="chapter" data-level="9.2" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html#tidy-the-data-1"><i class="fa fa-check"></i><b>9.2</b> Tidy the data</a></li>
<li class="chapter" data-level="9.3" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html#understand-the-data-2"><i class="fa fa-check"></i><b>9.3</b> Understand the data</a><ul>
<li class="chapter" data-level="9.3.1" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html#a.-transform-the-data"><i class="fa fa-check"></i><b>9.3.1</b> A. Transform the data</a></li>
<li class="chapter" data-level="9.3.2" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html#a.-vizualize-with-families."><i class="fa fa-check"></i><b>9.3.2</b> A. Vizualize with families.</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html#a.-visualize-with-cabins."><i class="fa fa-check"></i><b>9.4</b> A. Visualize with cabins.</a></li>
<li class="chapter" data-level="9.5" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html#b.-transform-dealing-with-missing-data."><i class="fa fa-check"></i><b>9.5</b> B. Transform Dealing with missing data.</a><ul>
<li class="chapter" data-level="9.5.1" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html#overview."><i class="fa fa-check"></i><b>9.5.1</b> Overview.</a></li>
<li class="chapter" data-level="9.5.2" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html#c.-transform-more-feature-engineering-with-the-ages-and-others."><i class="fa fa-check"></i><b>9.5.2</b> C. Transform More feature engineering with the ages and others.</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="case-study-predicting-survivalship-on-the-titanic.html"><a href="case-study-predicting-survivalship-on-the-titanic.html#references.-1"><i class="fa fa-check"></i><b>9.6</b> References.</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="case-study-text-classification-spam-and-ham-.html"><a href="case-study-text-classification-spam-and-ham-.html"><i class="fa fa-check"></i><b>10</b> Case Study - Text classification: Spam and Ham.</a></li>
<li class="chapter" data-level="11" data-path="case-study-wisconsin-breast-cancer.html"><a href="case-study-wisconsin-breast-cancer.html"><i class="fa fa-check"></i><b>11</b> Case Study - Wisconsin Breast Cancer</a><ul>
<li class="chapter" data-level="11.1" data-path="case-study-wisconsin-breast-cancer.html"><a href="case-study-wisconsin-breast-cancer.html#import-the-data-1"><i class="fa fa-check"></i><b>11.1</b> Import the data</a></li>
<li class="chapter" data-level="11.2" data-path="case-study-wisconsin-breast-cancer.html"><a href="case-study-wisconsin-breast-cancer.html#tidy-the-data-2"><i class="fa fa-check"></i><b>11.2</b> Tidy the data</a></li>
<li class="chapter" data-level="11.3" data-path="case-study-wisconsin-breast-cancer.html"><a href="case-study-wisconsin-breast-cancer.html#understand-the-data-3"><i class="fa fa-check"></i><b>11.3</b> Understand the data</a><ul>
<li class="chapter" data-level="11.3.1" data-path="case-study-wisconsin-breast-cancer.html"><a href="case-study-wisconsin-breast-cancer.html#transform-the-data-1"><i class="fa fa-check"></i><b>11.3.1</b> Transform the data</a></li>
<li class="chapter" data-level="11.3.2" data-path="case-study-wisconsin-breast-cancer.html"><a href="case-study-wisconsin-breast-cancer.html#pre-process-the-data"><i class="fa fa-check"></i><b>11.3.2</b> Pre-process the data</a></li>
<li class="chapter" data-level="11.3.3" data-path="case-study-wisconsin-breast-cancer.html"><a href="case-study-wisconsin-breast-cancer.html#model-the-data-1"><i class="fa fa-check"></i><b>11.3.3</b> Model the data</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="case-study-wisconsin-breast-cancer.html"><a href="case-study-wisconsin-breast-cancer.html#references-3"><i class="fa fa-check"></i><b>11.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>12</b> Final Words</a></li>
<li class="chapter" data-level="" data-path="references-4.html"><a href="references-4.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="knn---k-nearest-neighbour" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> KNN - K Nearest Neighbour</h1>
<p>The principle behind KNN classifier (K-Nearest Neighbor) algorithm is to find K predefined number of training samples that are closest in the distance to a new point &amp; predict a label for our new point using these samples.</p>
<div id="example-1.-prostate-cancer-dataset" class="section level2">
<h2><span class="header-section-number">5.1</span> Example 1. Prostate Cancer dataset</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
df &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;../bookdown-MachineLearningwithR/dataset/prostate_cancer.csv&quot;</span>)
<span class="kw">glimpse</span>(df)</code></pre></div>
<pre><code>## Observations: 100
## Variables: 10
## $ id                &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1...
## $ diagnosis_result  &lt;chr&gt; &quot;M&quot;, &quot;B&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;B&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;,...
## $ radius            &lt;int&gt; 23, 9, 21, 14, 9, 25, 16, 15, 19, 25, 24, 17...
## $ texture           &lt;int&gt; 12, 13, 27, 16, 19, 25, 26, 18, 24, 11, 21, ...
## $ perimeter         &lt;int&gt; 151, 133, 130, 78, 135, 83, 120, 90, 88, 84,...
## $ area              &lt;int&gt; 954, 1326, 1203, 386, 1297, 477, 1040, 578, ...
## $ smoothness        &lt;dbl&gt; 0.143, 0.143, 0.125, 0.070, 0.141, 0.128, 0....
## $ compactness       &lt;dbl&gt; 0.278, 0.079, 0.160, 0.284, 0.133, 0.170, 0....
## $ symmetry          &lt;dbl&gt; 0.242, 0.181, 0.207, 0.260, 0.181, 0.209, 0....
## $ fractal_dimension &lt;dbl&gt; 0.079, 0.057, 0.060, 0.097, 0.059, 0.076, 0....</code></pre>
<p>Change the diagnosis result into a factor</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df2 &lt;-<span class="st"> </span>df
df2$diagnosis_result &lt;-<span class="st"> </span><span class="kw">factor</span>(df2$diagnosis_result, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;B&quot;</span>, <span class="st">&quot;M&quot;</span>), 
                               <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Benign&quot;</span>, <span class="st">&quot;Malignant&quot;</span>))
df2 &lt;-<span class="st"> </span>df2 %&gt;%<span class="st"> </span><span class="kw">select</span>(-id)

<span class="kw">prop.table</span>(<span class="kw">table</span>(df2$diagnosis_result))</code></pre></div>
<pre><code>## 
##    Benign Malignant 
##      0.38      0.62</code></pre>
<p>Like with PCA, KNN is quite sensitve the scale of the variable. So it is important to first standardize the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)
param_preproc_df2 &lt;-<span class="st"> </span><span class="kw">preProcess</span>(df2[,<span class="dv">2</span>:<span class="dv">9</span>], <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;scale&quot;</span>, <span class="st">&quot;center&quot;</span>))
preproc_df2 &lt;-<span class="st"> </span><span class="kw">predict</span>(param_preproc_df2, df2[, <span class="dv">2</span>:<span class="dv">9</span>])
<span class="kw">summary</span>(preproc_df2)</code></pre></div>
<pre><code>##      radius            texture          perimeter            area        
##  Min.   :-1.60891   Min.   :-1.3923   Min.   :-1.8914   Min.   :-1.5667  
##  1st Qu.:-0.99404   1st Qu.:-0.8146   1st Qu.:-0.6031   1st Qu.:-0.7073  
##  Median : 0.03074   Median :-0.1406   Median :-0.1174   Median :-0.1842  
##  Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  
##  3rd Qu.: 0.85057   3rd Qu.: 0.7741   3rd Qu.: 0.7379   3rd Qu.: 0.6697  
##  Max.   : 1.67039   Max.   : 1.6888   Max.   : 3.1770   Max.   : 3.6756  
##    smoothness        compactness         symmetry       fractal_dimension
##  Min.   :-2.23539   Min.   :-1.4507   Min.   :-1.8896   Min.   :-1.4342  
##  1st Qu.:-0.63039   1st Qu.:-0.7556   1st Qu.:-0.6877   1st Qu.:-0.6981  
##  Median :-0.04986   Median :-0.1341   Median :-0.1030   Median :-0.2073  
##  Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  
##  3rd Qu.: 0.63312   3rd Qu.: 0.4956   3rd Qu.: 0.5142   3rd Qu.: 0.5288  
##  Max.   : 2.75035   Max.   : 3.5703   Max.   : 3.6001   Max.   : 3.9639</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">preproc_df2 &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(<span class="dt">diagnosis =</span> df2$diagnosis_result, preproc_df2)

param_split_df2&lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(df2$diagnosis_result, <span class="dt">times =</span> <span class="dv">1</span>, <span class="dt">p =</span> <span class="fl">0.8</span>, 
                                      <span class="dt">list =</span> <span class="ot">FALSE</span>)
train_df2 &lt;-<span class="st"> </span>preproc_df2[param_split_df2, ]
test_df2 &lt;-<span class="st"> </span>preproc_df2[-param_split_df2, ]

<span class="co">#We can check that we still have the same kind of split</span>
<span class="kw">prop.table</span>(<span class="kw">table</span>(train_df2$diagnosis))</code></pre></div>
<pre><code>## 
##    Benign Malignant 
##  0.382716  0.617284</code></pre>
</div>
<div id="example-2.-wine-dataset" class="section level2">
<h2><span class="header-section-number">5.2</span> Example 2. Wine dataset</h2>
<p>We load the dataset and do some quick cleaning</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;../bookdown-MachineLearningwithR/dataset/Wine_UCI.csv&quot;</span>, <span class="dt">col_names =</span> <span class="ot">FALSE</span>)
<span class="kw">colnames</span>(df) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Origin&quot;</span>, <span class="st">&quot;Alcohol&quot;</span>, <span class="st">&quot;Malic_acid&quot;</span>, <span class="st">&quot;Ash&quot;</span>, <span class="st">&quot;Alkalinity_of_ash&quot;</span>, 
                  <span class="st">&quot;Magnesium&quot;</span>, <span class="st">&quot;Total_phenols&quot;</span>, <span class="st">&quot;Flavanoids&quot;</span>, <span class="st">&quot;Nonflavonoids_phenols&quot;</span>, 
                  <span class="st">&quot;Proanthocyanins&quot;</span>, <span class="st">&quot;Color_intensity&quot;</span>, <span class="st">&quot;Hue&quot;</span>, <span class="st">&quot;OD280_OD315_diluted_wines&quot;</span>, 
                  <span class="st">&quot;Proline&quot;</span>)

<span class="kw">glimpse</span>(df)</code></pre></div>
<pre><code>## Observations: 178
## Variables: 14
## $ Origin                    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
## $ Alcohol                   &lt;dbl&gt; 14.23, 13.20, 13.16, 14.37, 13.24, 1...
## $ Malic_acid                &lt;dbl&gt; 1.71, 1.78, 2.36, 1.95, 2.59, 1.76, ...
## $ Ash                       &lt;dbl&gt; 2.43, 2.14, 2.67, 2.50, 2.87, 2.45, ...
## $ Alkalinity_of_ash         &lt;dbl&gt; 15.6, 11.2, 18.6, 16.8, 21.0, 15.2, ...
## $ Magnesium                 &lt;int&gt; 127, 100, 101, 113, 118, 112, 96, 12...
## $ Total_phenols             &lt;dbl&gt; 2.80, 2.65, 2.80, 3.85, 2.80, 3.27, ...
## $ Flavanoids                &lt;dbl&gt; 3.06, 2.76, 3.24, 3.49, 2.69, 3.39, ...
## $ Nonflavonoids_phenols     &lt;dbl&gt; 0.28, 0.26, 0.30, 0.24, 0.39, 0.34, ...
## $ Proanthocyanins           &lt;dbl&gt; 2.29, 1.28, 2.81, 2.18, 1.82, 1.97, ...
## $ Color_intensity           &lt;dbl&gt; 5.64, 4.38, 5.68, 7.80, 4.32, 6.75, ...
## $ Hue                       &lt;dbl&gt; 1.04, 1.05, 1.03, 0.86, 1.04, 1.05, ...
## $ OD280_OD315_diluted_wines &lt;dbl&gt; 3.92, 3.40, 3.17, 3.45, 2.93, 2.85, ...
## $ Proline                   &lt;int&gt; 1065, 1050, 1185, 1480, 735, 1450, 1...</code></pre>
<p>The origin is our dependent variable. Let’s make it a factor.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df$Origin &lt;-<span class="st"> </span><span class="kw">as.factor</span>(df$Origin)

<span class="co">#Let&#39;s check our explained variable distribution of origin</span>
<span class="kw">round</span>(<span class="kw">prop.table</span>(<span class="kw">table</span>(df$Origin)), <span class="dv">2</span>)</code></pre></div>
<pre><code>## 
##    1    2    3 
## 0.33 0.40 0.27</code></pre>
<p>That’s nice, our explained variable is almost equally distributed with the 3 set of origin.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Let&#39;s also check if we have any NA values</span>
<span class="kw">summary</span>(df)</code></pre></div>
<pre><code>##  Origin    Alcohol        Malic_acid         Ash        Alkalinity_of_ash
##  1:59   Min.   :11.03   Min.   :0.740   Min.   :1.360   Min.   :10.60    
##  2:71   1st Qu.:12.36   1st Qu.:1.603   1st Qu.:2.210   1st Qu.:17.20    
##  3:48   Median :13.05   Median :1.865   Median :2.360   Median :19.50    
##         Mean   :13.00   Mean   :2.336   Mean   :2.367   Mean   :19.49    
##         3rd Qu.:13.68   3rd Qu.:3.083   3rd Qu.:2.558   3rd Qu.:21.50    
##         Max.   :14.83   Max.   :5.800   Max.   :3.230   Max.   :30.00    
##    Magnesium      Total_phenols     Flavanoids    Nonflavonoids_phenols
##  Min.   : 70.00   Min.   :0.980   Min.   :0.340   Min.   :0.1300       
##  1st Qu.: 88.00   1st Qu.:1.742   1st Qu.:1.205   1st Qu.:0.2700       
##  Median : 98.00   Median :2.355   Median :2.135   Median :0.3400       
##  Mean   : 99.74   Mean   :2.295   Mean   :2.029   Mean   :0.3619       
##  3rd Qu.:107.00   3rd Qu.:2.800   3rd Qu.:2.875   3rd Qu.:0.4375       
##  Max.   :162.00   Max.   :3.880   Max.   :5.080   Max.   :0.6600       
##  Proanthocyanins Color_intensity       Hue        
##  Min.   :0.410   Min.   : 1.280   Min.   :0.4800  
##  1st Qu.:1.250   1st Qu.: 3.220   1st Qu.:0.7825  
##  Median :1.555   Median : 4.690   Median :0.9650  
##  Mean   :1.591   Mean   : 5.058   Mean   :0.9574  
##  3rd Qu.:1.950   3rd Qu.: 6.200   3rd Qu.:1.1200  
##  Max.   :3.580   Max.   :13.000   Max.   :1.7100  
##  OD280_OD315_diluted_wines    Proline      
##  Min.   :1.270             Min.   : 278.0  
##  1st Qu.:1.938             1st Qu.: 500.5  
##  Median :2.780             Median : 673.5  
##  Mean   :2.612             Mean   : 746.9  
##  3rd Qu.:3.170             3rd Qu.: 985.0  
##  Max.   :4.000             Max.   :1680.0</code></pre>
<p>Here we noticed that the range of values in our variable is quite wide. It means our data will need to be standardize. We also note that we no “NA” values. That’s quite a nice surprise!</p>
<div id="understand-the-data" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Understand the data</h3>
<p>We first slide our data in a training and testing set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df2 &lt;-<span class="st"> </span>df
param_split_df2 &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(df2$Origin, <span class="dt">p =</span> <span class="fl">0.75</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)

train_df2 &lt;-<span class="st"> </span>df2[param_split_df2, ]
test_df2 &lt;-<span class="st"> </span>df2[-param_split_df2, ]</code></pre></div>
<p>The great with caret is we can standardize our data in the the training phase.</p>
<div id="model-the-data" class="section level4">
<h4><span class="header-section-number">5.2.1.1</span> Model the data</h4>
<p>Let’s keep using <code>caret</code> for our training.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trnctrl_df2 &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>, <span class="dt">repeats =</span> <span class="dv">3</span>)
model_knn_df2 &lt;-<span class="st"> </span><span class="kw">train</span>(Origin ~., <span class="dt">data =</span> train_df2, <span class="dt">method =</span> <span class="st">&quot;knn&quot;</span>, 
                       <span class="dt">trControl =</span> trnctrl_df2, 
                       <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),  
                       <span class="dt">tuneLength =</span> <span class="dv">10</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_knn_df2</code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 135 samples
##  13 predictor
##   3 classes: &#39;1&#39;, &#39;2&#39;, &#39;3&#39; 
## 
## Pre-processing: centered (13), scaled (13) 
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 122, 121, 122, 121, 120, 121, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa    
##    5  0.9697253  0.9544585
##    7  0.9681074  0.9518094
##    9  0.9633455  0.9448680
##   11  0.9652015  0.9476770
##   13  0.9675824  0.9511580
##   15  0.9705128  0.9556658
##   17  0.9752747  0.9628869
##   19  0.9778388  0.9667217
##   21  0.9802198  0.9701749
##   23  0.9800366  0.9698333
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was k = 21.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(model_knn_df2)</code></pre></div>
<p><img src="machinelearningwithR_files/figure-html/plot01_knn-1.png" width="672" /></p>
<p>Let’s use our model to make our prediction</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prediction_knn_df2 &lt;-<span class="st"> </span><span class="kw">predict</span>(model_knn_df2, <span class="dt">newdata =</span> test_df2)

<span class="kw">confusionMatrix</span>(prediction_knn_df2, <span class="dt">reference =</span> test_df2$Origin)</code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  1  2  3
##          1 14  1  0
##          2  0 15  0
##          3  0  1 12
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9535          
##                  95% CI : (0.8419, 0.9943)
##     No Information Rate : 0.3953          
##     P-Value [Acc &gt; NIR] : 1.02e-14        
##                                           
##                   Kappa : 0.93            
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: 1 Class: 2 Class: 3
## Sensitivity            1.0000   0.8824   1.0000
## Specificity            0.9655   1.0000   0.9677
## Pos Pred Value         0.9333   1.0000   0.9231
## Neg Pred Value         1.0000   0.9286   1.0000
## Prevalence             0.3256   0.3953   0.2791
## Detection Rate         0.3256   0.3488   0.2791
## Detection Prevalence   0.3488   0.3488   0.3023
## Balanced Accuracy      0.9828   0.9412   0.9839</code></pre>
</div>
</div>
</div>
<div id="references-1" class="section level2">
<h2><span class="header-section-number">5.3</span> References</h2>
<ul>
<li>KNN R, K-Nearest neighbor implementation in R using caret package. <a href="http://dataaspirant.com/2017/01/09/knn-implementation-r-using-caret-package/">Here</a></li>
<li></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="trees-and-classification.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/fderyckel/bookdown-demo/edit/master/06-knn.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
